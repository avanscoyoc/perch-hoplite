{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfDwaWNTZCZ"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook uses perch-hoplite to compute and save embeddings for set of audio files using a pre-trained model. This is the first step in the agile modeling process. If the data you wish to search and classify is already embedded with a pre-trained model into a perch-hoplite database, then proceed to the step 2 colab notebook ([2_agile_modeling_v2.ipynb](https://github.com/google-research/perch-hoplite/blob/main/perch_hoplite/agile/2_agile_modeling_v2.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Db84ySxSJYA"
      },
      "source": [
        "## [Optional] perch-hoplite installation for hosted runtimes\n",
        "\n",
        "If you have not already installed perch-hoplite (particularly if you are using a hosted Colab runtime), make sure to install perch-hoplite from the Github source to ensure the most recent version is installed. After installation, you will need to restart your runtime before running anything else. Go to the top menu, select \"Runtime\" then \"Restart Session\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D7bUZkS_Rawd",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "#@title Only run this code if you need to install perch-hoplite\n",
        "#!pip install git+https://github.com/google-research/perch-hoplite.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GTtVnkC-6_i7"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "from etils import epath\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from perch_hoplite.agile import colab_utils\n",
        "from perch_hoplite.agile import embed\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db import brutalism\n",
        "from perch_hoplite.db import interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T4vILrO80iP"
      },
      "source": [
        "# Embed the audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c6zdGxl68vft"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgileConfigs(audio_sources_config=AudioSources(audio_globs=(AudioSourceConfig(dataset_name='mojave_data', base_path='/mnt/mojave/Birds', file_glob='BD-*/*.wav', min_audio_len_s=1.0, target_sample_rate_hz=-2, shard_len_s=60.0, max_shards_per_file=None),)), db_config=DBConfig(db_key='sqlite_usearch', db_config=db_path: !!python/object/apply:etils.epath.gpath.PosixGPath\n",
              "- /\n",
              "- mnt\n",
              "- mojave\n",
              "- Birds\n",
              "usearch_cfg:\n",
              "  dtype: float16\n",
              "  embedding_dim: 1280\n",
              "  expansion_add: 256\n",
              "  expansion_search: 128\n",
              "  metric_name: IP\n",
              "), model_config=ModelConfig(model_key='taxonomy_model_tf', embedding_dim=1280, model_config=hop_size_s: 5.0\n",
              "model_path: ''\n",
              "sample_rate: 32000\n",
              "tfhub_version: 8\n",
              "window_size_s: 5.0\n",
              "))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Configuration { vertical-output: true }\n",
        "\n",
        "# @markdown Configure the raw dataset and output location(s).  The format is a mapping from\n",
        "# @markdown a dataset_name to a (base_path, fileglob) pair.  Note that the file\n",
        "# @markdown globs are case sensitive.  The dataset name can be anything you want.\n",
        "#\n",
        "# @markdown This structure allows you to move your data around without having to\n",
        "# @markdown re-embed the dataset.  The generated embedding database will be\n",
        "# @markdown placed in the base path. This allows you to simply swap out\n",
        "# @markdown the base path here if you ever move your dataset.\n",
        "\n",
        "# @markdown By default we only process one dataset at a time.  Re-run this entire notebook\n",
        "# @markdown once per dataset.\n",
        "\n",
        "# @markdown For example, we might set dataset_base_path to '/home/me/myproject',\n",
        "# @markdown and use the glob '\\*/\\*.wav' if all of the audio files have filepaths\n",
        "# @markdown like '/home/me/myproject/site_XYZ/audio_ABC.wav' (e.g. audio files are contained in subfolders of the base directory).\n",
        "\n",
        "# @markdown 1. Create a unique name for the database that will store the embeddings for the target data.\n",
        "dataset_name = 'mojave_data'  # @param {type:'string'}\n",
        "# @markdown 2. Input the filepath for the folder that is containing the input audio files.\n",
        "dataset_base_path = '/mnt/mojave/Birds'  #@param {type:'string'}\n",
        "# @markdown 3. Input the file pattern for the audio files within that folder that you want to embed. Some examples for how to input:\n",
        "# @markdown - All files in the base directory of a specific type (not subdirectories): e.g. `*.wav` (or `*.flac` etc) will generate embeddings for all .wav files (or whichever format) in the dataset_base_path\n",
        "# @markdown - All files in one level of subdirectories within the base directory: `*/*.flac` will generate embeddings for all .flac files\n",
        "# @markdown - Single file: `myfile.wav` will only embed the audio from that specific file.\n",
        "dataset_fileglob = 'BD-*/*.wav'  # @param {type:'string'}\n",
        "\n",
        "# @markdown 4. [Optional] If saving the embeddings database to a new directory, specify here.\n",
        "# @markdown Otherwise, leave blank - by default the embeddings database output will be saved within\n",
        "# @markdown dataset_base_path where the audio is located. You do not need to specify db_path unless you want to maintain multiple\n",
        "# @markdown distinct embedding databases, or if you would like to save the output\n",
        "# @markdown in a different folder. If your input audio data is accessed\n",
        "# @markdown from a public URL, we recommend specifying a separate output directory here.\n",
        "db_path = ''  # @param {type:'string'}\n",
        "if not db_path or db_path == 'None':\n",
        "  db_path = None\n",
        "\n",
        "# @markdown 5. Choose a supported model to generate embeddings: `perch_8` or `birdnet_v2.3` are most common\n",
        "# @markdown for birds. Other choices include `surfperch` for coral reefs or\n",
        "# @markdown `multispecies_whale` for marine mammals.\n",
        "model_choice = 'perch_8'  #@param['perch_8', 'humpback', 'multispecies_whale', 'surfperch', 'birdnet_V2.3']\n",
        "\n",
        "# @markdown 6. [Optional] Shard the audio for embeddings. File sharding automatically splits audio files into smaller chunks\n",
        "# @markdown for creating embeddings. This limits both system and GPU memory usage,\n",
        "# @markdown especially useful when working with long files (>1 hour).\n",
        "use_file_sharding = True  # @param {type:'boolean'}\n",
        "# @markdown If you want to change the length in seconds for the shards, specify here.\n",
        "shard_length_in_seconds = 60  # @param {type:'number'}\n",
        "\n",
        "audio_glob = source_info.AudioSourceConfig(\n",
        "    dataset_name=dataset_name,\n",
        "    base_path=dataset_base_path,\n",
        "    file_glob=dataset_fileglob,\n",
        "    min_audio_len_s=1.0,\n",
        "    target_sample_rate_hz=-2,\n",
        "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\n",
        ")\n",
        "\n",
        "configs = colab_utils.load_configs(\n",
        "    source_info.AudioSources((audio_glob,)),\n",
        "    db_path,\n",
        "    model_config_key=model_choice,\n",
        "    db_key='sqlite_usearch',\n",
        ")\n",
        "configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NN9Uyy1yqAWS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized DB located at  /mnt/mojave/Birds\n"
          ]
        }
      ],
      "source": [
        "#@title Initialize the hoplite database (DB) { vertical-output: true }\n",
        "global db\n",
        "db = configs.db_config.load_db()\n",
        "num_embeddings = db.count_embeddings()\n",
        "\n",
        "print('Initialized DB located at ', configs.db_config.db_config.db_path)\n",
        "\n",
        "def drop_and_reload_db(_) -> interface.HopliteDBInterface:\n",
        "  db_path = epath.Path(configs.db_config.db_config.db_path)\n",
        "  for fp in db_path.glob('hoplite.sqlite*'):\n",
        "    fp.unlink()\n",
        "  (db_path / 'usearch.index').unlink()\n",
        "  print('\\n Deleted previous db at: ', configs.db_config.db_config.db_path)\n",
        "  db = configs.db_config.load_db()\n",
        "\n",
        "#@markdown If `drop_existing_db` set to True, when the database already exists and contains embeddings,\n",
        "#@markdown then those existing embeddings will be erased. You will be prompted to confirm you wish to delete those existing\n",
        "#@markdown embeddings. If you want to keep existing embeddings in the database, then set to False, which will append the new\n",
        "#@markdown embeddings to the database.\n",
        "drop_existing_db = True  #@param {type:'boolean'}\n",
        "\n",
        "if num_embeddings > 0 and drop_existing_db:\n",
        "  print('Existing DB contains datasets: ', db.get_dataset_names())\n",
        "  print('num embeddings: ', num_embeddings)\n",
        "  print('\\n\\nClick the button below to confirm you really want to drop the database at ')\n",
        "  print(f'{configs.db_config.db_config.db_path}\\n')\n",
        "  print(f'This will permanently delete all {num_embeddings} embeddings from the existing database.\\n')\n",
        "  print('If you do NOT want to delete this data, set `drop_existing_db` above to `False` and re-run this cell.\\n')\n",
        "\n",
        "  button = widgets.Button(description='Delete database?')\n",
        "  button.on_click(drop_and_reload_db)\n",
        "  display(button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MnGWbhc0LhiU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding dataset: mojave_data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.venv/lib/python3.11/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n",
            "  0%|          | 0/555 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1755023717.529847    4125 service.cc:152] XLA service 0xaaab29228420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1755023717.529873    4125 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
            "2025-08-12 18:35:17.674842: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-08-12 18:35:17.707416: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
            "I0000 00:00:1755023718.426056    4125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2025-08-12 18:35:18.430684: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 181400224 exceeds 10% of free system memory.\n",
            "2025-08-12 18:35:19.325592: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 181400224 exceeds 10% of free system memory.\n",
            "2025-08-12 18:35:20.159335: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 181400224 exceeds 10% of free system memory.\n",
            "2025-08-12 18:35:20.988215: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 181400224 exceeds 10% of free system memory.\n",
            "2025-08-12 18:35:21.808659: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 181400224 exceeds 10% of free system memory.\n",
            "  0%|          | 1/555 [00:55<8:29:00, 55.13s/it]2025-08-12 18:36:55.161798: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
            " 10%|▉         | 55/555 [45:24<7:00:23, 50.45s/it]ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-30739B/30739B__0__20230524_230001.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-30739B/30739B__0__20230524_230001.wav'>: Format not recognised..\n",
            " 21%|██        | 117/555 [1:35:39<6:02:52, 49.71s/it]ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-30925A/30925A__0__20230525_050000.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-30925A/30925A__0__20230525_050000.wav'>: Format not recognised..\n",
            " 29%|██▉       | 162/555 [2:11:32<5:20:40, 48.96s/it]ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-30925B/30925B__0__20230524_010001.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-30925B/30925B__0__20230524_010001.wav'>: Format not recognised..\n",
            " 44%|████▎     | 242/555 [3:38:38<4:16:36, 49.19s/it]  ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-30625B/30625B__0__20230527_020001.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-30625B/30625B__0__20230527_020001.wav'>: Format not recognised..\n",
            " 52%|█████▏    | 287/555 [4:14:59<3:42:20, 49.78s/it]ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-30739A/30739A__0__20230524_010000.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-30739A/30739A__0__20230524_010000.wav'>: Format not recognised..\n",
            " 52%|█████▏    | 289/555 [4:15:49<2:49:32, 38.24s/it]2025-08-12 22:51:50.486837: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
            " 52%|█████▏    | 291/555 [4:17:28<3:10:41, 43.34s/it]2025-08-12 22:53:29.354992: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
            " 54%|█████▎    | 297/555 [4:22:23<3:27:36, 48.28s/it]2025-08-12 22:58:24.426082: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
            " 95%|█████████▌| 530/555 [9:05:27<20:44, 49.79s/it]     ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-31457A/31457A__0__20230525_040001.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-31457A/31457A__0__20230525_040001.wav'>: Format not recognised..\n",
            "100%|█████████▉| 554/555 [9:24:46<00:50, 50.57s/it]ERROR:absl:Failed to parse audio file (/mnt/mojave/Birds/BD-31457B/31457B__0__20230522_060001.wav) : Error opening <_io.BufferedReader name='/mnt/mojave/Birds/BD-31457B/31457B__0__20230522_060001.wav'>: Format not recognised..\n",
            "100%|██████████| 555/555 [9:24:46<00:00, 61.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Embedding complete, total embeddings:  393785\n"
          ]
        }
      ],
      "source": [
        "#@title Run the embedding { vertical-output: true }\n",
        "\n",
        "print(f'Embedding dataset: {audio_glob.dataset_name}')\n",
        "\n",
        "worker = embed.EmbedWorker(\n",
        "    audio_sources=configs.audio_sources_config,\n",
        "    db=db,\n",
        "    model_config=configs.model_config)\n",
        "\n",
        "worker.process_all(target_dataset_name=audio_glob.dataset_name)\n",
        "\n",
        "print('\\n\\nEmbedding complete, total embeddings: ', db.count_embeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HvVuFw-somHe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset 'mojave_data':\n",
            "\tnum embeddings:  393785\n"
          ]
        }
      ],
      "source": [
        "#@title Per dataset statistics { vertical-output: true }\n",
        "\n",
        "for dataset in db.get_dataset_names():\n",
        "  print(f'\\nDataset \\'{dataset}\\':')\n",
        "  print('\\tnum embeddings: ', db.get_embeddings_by_source(dataset, source_id=None).shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "ihBNRbwuuwal"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4.95 s, sys: 5.18 ms, total: 4.96 s\n",
            "Wall time: 4.96 s\n",
            "[1, 232, 172176, 90, 10253, 10269, 34, 172139, 171956, 10273, 190, 10395, 171968, 172110, 10328, 158, 205, 5, 10305, 188, 33, 17, 172, 10230, 9, 10176, 172145, 10337, 10314, 161, 83458, 207, 10332, 172182, 240, 185, 172163, 10177, 4, 10330, 100, 20, 10284, 171943, 172160, 172174, 28, 10182, 88, 186, 83468, 10360, 172162, 10379, 171958, 10329, 35, 10188, 202, 83465, 175, 83451, 117, 172179, 30, 10283, 10320, 7, 10373, 10318, 10236, 172107, 83515, 10324, 10393, 10247, 10301, 10371, 169, 22, 183, 38, 97, 200, 27, 172183, 36, 172113, 10326, 10307, 10354, 154, 10174, 8, 182168, 182240, 10220, 11, 121, 172099, 178, 94, 10260, 10268, 253, 83687, 109, 10217, 171949, 10384, 10357, 10184, 10343, 172158, 191, 208, 172177, 182158, 170, 10189, 12, 171951, 182313, 182279, 10355, 10258, 306, 10281]\n"
          ]
        }
      ],
      "source": [
        "#@title Show example embedding search\n",
        "#@markdown As an example (and to show that the embedding process worked), this\n",
        "#@markdown selects a single embedding from the database and outputs the embedding ids of the\n",
        "#@markdown top-K (k = 128) nearest neighbors in the database.\n",
        "\n",
        "q = db.get_embedding(db.get_one_embedding_id())\n",
        "%time results, scores = brutalism.brute_search(worker.db, query_embedding=q, search_list_size=128, score_fn=np.dot)\n",
        "print([int(r.embedding_id) for r in results])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//gdm/sustainability/perch:perch_notebook",
        "kind": "private"
      },
      "name": "v2_1_embed_unlabeled_audio.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1ePT3-fDB3kA3_T7trthFtu8xTJQWQBoQ",
          "timestamp": 1723499538314
        }
      ]
    },
    "kernelspec": {
      "display_name": "perch-hoplite-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
